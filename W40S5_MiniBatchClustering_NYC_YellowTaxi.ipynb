{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 2905525,
          "sourceType": "datasetVersion",
          "datasetId": 1777799
        }
      ],
      "dockerImageVersionId": 30626,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "MiniBatchClustering-NYC_YellowTaxi",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mmilannaik/bostonhousepricing/blob/main/W40S5_MiniBatchClustering_NYC_YellowTaxi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "elemento_nyc_yellow_taxi_trip_data_path = kagglehub.dataset_download('elemento/nyc-yellow-taxi-trip-data')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "fFjuvUeMOEL6",
        "outputId": "723d8ee7-4b7d-4716-da60-149aea7f1efc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/elemento/nyc-yellow-taxi-trip-data?dataset_version_number=2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.78G/1.78G [00:25<00:00, 75.6MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-01-04T12:34:41.316581Z",
          "iopub.execute_input": "2024-01-04T12:34:41.316959Z",
          "iopub.status.idle": "2024-01-04T12:34:41.900164Z",
          "shell.execute_reply.started": "2024-01-04T12:34:41.31693Z",
          "shell.execute_reply": "2024-01-04T12:34:41.898495Z"
        },
        "trusted": true,
        "id": "pMMtXRncOEL9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import MiniBatchKMeans"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-04T12:34:41.902938Z",
          "iopub.execute_input": "2024-01-04T12:34:41.903711Z",
          "iopub.status.idle": "2024-01-04T12:34:42.994568Z",
          "shell.execute_reply.started": "2024-01-04T12:34:41.903652Z",
          "shell.execute_reply": "2024-01-04T12:34:42.993523Z"
        },
        "trusted": true,
        "id": "25KEpeAcOEL9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/kaggle/input/nyc-yellow-taxi-trip-data/yellow_tripdata_2016-01.csv\")\n",
        "data.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-04T12:34:44.936758Z",
          "iopub.execute_input": "2024-01-04T12:34:44.937294Z",
          "iopub.status.idle": "2024-01-04T12:35:43.601948Z",
          "shell.execute_reply.started": "2024-01-04T12:34:44.937247Z",
          "shell.execute_reply": "2024-01-04T12:35:43.600742Z"
        },
        "trusted": true,
        "id": "-1GR1ZzsOEL-",
        "outputId": "145980f1-e2e4-4ff9-bf72-8cf39e84c4dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/kaggle/input/nyc-yellow-taxi-trip-data/yellow_tripdata_2016-01.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-4070e5aa208b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/kaggle/input/nyc-yellow-taxi-trip-data/yellow_tripdata_2016-01.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/nyc-yellow-taxi-trip-data/yellow_tripdata_2016-01.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-04T12:35:43.60422Z",
          "iopub.execute_input": "2024-01-04T12:35:43.604704Z",
          "iopub.status.idle": "2024-01-04T12:35:43.644802Z",
          "shell.execute_reply.started": "2024-01-04T12:35:43.604669Z",
          "shell.execute_reply": "2024-01-04T12:35:43.643401Z"
        },
        "trusted": true,
        "id": "SxUjV68QOEL-",
        "outputId": "d52e724c-dae9-475a-e72e-f717537ef47c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'data' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-304fa4ce4ebd>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.isna().sum()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-04T12:35:43.646505Z",
          "iopub.execute_input": "2024-01-04T12:35:43.646961Z",
          "iopub.status.idle": "2024-01-04T12:35:47.245351Z",
          "shell.execute_reply.started": "2024-01-04T12:35:43.646925Z",
          "shell.execute_reply": "2024-01-04T12:35:47.24424Z"
        },
        "trusted": true,
        "id": "cLJWa7toOEL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Wf4-5fJ8OEL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.Pre-Processing"
      ],
      "metadata": {
        "id": "k0zLXGSpOEL_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the data\n",
        "# data = pd.read_csv('/kaggle/input/nyc-yellow-taxi-trip-data/yellow_tripdata_2016-01.csv')\n",
        "\n",
        "# Convert Y/N to 1/0\n",
        "data['store_and_fwd_flag'] = LabelEncoder().fit_transform(data['store_and_fwd_flag'])\n",
        "\n",
        "# Convert timestamp columns to datetime\n",
        "data['tpep_pickup_datetime'] = pd.to_datetime(data['tpep_pickup_datetime'])\n",
        "data['tpep_dropoff_datetime'] = pd.to_datetime(data['tpep_dropoff_datetime'])\n",
        "\n",
        "# Extract features from timestamp columns (hour, day, month)\n",
        "data['pickup_hour'] = data['tpep_pickup_datetime'].dt.hour\n",
        "data['pickup_day'] = data['tpep_pickup_datetime'].dt.day\n",
        "data['pickup_month'] = data['tpep_pickup_datetime'].dt.month\n",
        "data['dropoff_hour'] = data['tpep_dropoff_datetime'].dt.hour\n",
        "data['dropoff_day'] = data['tpep_dropoff_datetime'].dt.day\n",
        "data['dropoff_month'] = data['tpep_dropoff_datetime'].dt.month\n",
        "\n",
        "# Drop unnecessary columns\n",
        "data.drop(['tpep_pickup_datetime', 'tpep_dropoff_datetime'], axis=1, inplace=True)\n",
        "\n",
        "# Standardize numerical features\n",
        "numerical_features = ['trip_distance', 'pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude', 'fare_amount', 'extra', 'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge', 'total_amount']\n",
        "data[numerical_features] = StandardScaler().fit_transform(data[numerical_features])\n",
        "\n",
        "# Display the preprocessed data\n",
        "data.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-04T12:35:47.250516Z",
          "iopub.execute_input": "2024-01-04T12:35:47.250892Z",
          "iopub.status.idle": "2024-01-04T12:36:10.024547Z",
          "shell.execute_reply.started": "2024-01-04T12:35:47.250854Z",
          "shell.execute_reply": "2024-01-04T12:36:10.023342Z"
        },
        "trusted": true,
        "id": "6T5Dv_5LOEMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.payment_type.value_counts()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-04T12:44:42.521193Z",
          "iopub.execute_input": "2024-01-04T12:44:42.52164Z",
          "iopub.status.idle": "2024-01-04T12:44:42.633915Z",
          "shell.execute_reply.started": "2024-01-04T12:44:42.521603Z",
          "shell.execute_reply": "2024-01-04T12:44:42.632869Z"
        },
        "trusted": true,
        "id": "WgLQH6qTOEMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Determine No of Clusters"
      ],
      "metadata": {
        "id": "7sohqvc-OEMC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-04T12:36:15.15636Z",
          "iopub.execute_input": "2024-01-04T12:36:15.15678Z",
          "iopub.status.idle": "2024-01-04T12:36:15.164503Z",
          "shell.execute_reply.started": "2024-01-04T12:36:15.156748Z",
          "shell.execute_reply": "2024-01-04T12:36:15.163467Z"
        },
        "trusted": true,
        "id": "lMdtRp6DOEMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-04T12:42:31.681314Z",
          "iopub.execute_input": "2024-01-04T12:42:31.681769Z",
          "iopub.status.idle": "2024-01-04T12:42:31.689548Z",
          "shell.execute_reply.started": "2024-01-04T12:42:31.681725Z",
          "shell.execute_reply": "2024-01-04T12:42:31.688151Z"
        },
        "trusted": true,
        "id": "-fhy4nfsOEMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select all features for clustering\n",
        "features_for_clustering = ['pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude',\n",
        "                               'passenger_count', 'trip_distance', 'fare_amount', 'extra', 'mta_tax',\n",
        "                               'tip_amount', 'tolls_amount', 'improvement_surcharge', 'total_amount', 'pickup_hour', 'pickup_day',\n",
        "       'pickup_month', 'dropoff_hour', 'dropoff_day', 'dropoff_month']\n",
        "len(features_for_clustering)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-04T12:45:49.366665Z",
          "iopub.execute_input": "2024-01-04T12:45:49.367069Z",
          "iopub.status.idle": "2024-01-04T12:45:49.37468Z",
          "shell.execute_reply.started": "2024-01-04T12:45:49.367038Z",
          "shell.execute_reply": "2024-01-04T12:45:49.37365Z"
        },
        "trusted": true,
        "id": "pnCmJ064OEMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import MiniBatchKMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Deciding no of clusters upon 10Lakhs Sample\n",
        "X = data[features_for_clustering].sample(100000)\n",
        "\n",
        "# Assuming 'data' is your pre-processed DataFrame\n",
        "n_samples = len(X)\n",
        "n_clusters_range = range(2, 11)  # Number of clusters range from 2 to 10\n",
        "\n",
        "# Specify the number of chunks\n",
        "n_chunks = 10\n",
        "chunk_size = n_samples // n_chunks\n",
        "\n",
        "# Placeholder for silhouette scores\n",
        "silhouette_scores = []\n",
        "inertia = []\n",
        "\n",
        "# Loop through different cluster numbers\n",
        "for n_clusters in n_clusters_range:\n",
        "    # Initialize MiniBatchKMeans\n",
        "    mbkmeans = MiniBatchKMeans(n_clusters=n_clusters, random_state=42, n_init='auto', batch_size=10000)\n",
        "\n",
        "    # Loop through chunks\n",
        "    for i in range(n_chunks):\n",
        "        # Determine start and end index for the chunk\n",
        "        start_idx = i * chunk_size\n",
        "        end_idx = (i + 1) * chunk_size if i < n_chunks - 1 else n_samples\n",
        "\n",
        "        # Extract the chunk\n",
        "        chunk = X.iloc[start_idx:end_idx]\n",
        "\n",
        "\n",
        "        # Partially fit the model on the chunk\n",
        "        mbkmeans.partial_fit(chunk)\n",
        "\n",
        "\n",
        "    # Predict clusters for all data points\n",
        "    labels = mbkmeans.predict(X)\n",
        "\n",
        "    # Inertia\n",
        "    inertia.append(mbkmeans.inertia_)\n",
        "    # Calculate silhouette score\n",
        "    silhouette = silhouette_score(X, labels)\n",
        "    silhouette_scores.append(silhouette)\n",
        "    print(f\"Training for No of Clusters- {n_clusters} completed!!\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-04T13:30:51.347619Z",
          "iopub.execute_input": "2024-01-04T13:30:51.348113Z",
          "iopub.status.idle": "2024-01-04T13:49:15.093728Z",
          "shell.execute_reply.started": "2024-01-04T13:30:51.348076Z",
          "shell.execute_reply": "2024-01-04T13:49:15.092012Z"
        },
        "trusted": true,
        "id": "ajN40UqpOEMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot the silhouette scores\n",
        "plt.plot(n_clusters_range, silhouette_scores, marker='o')\n",
        "plt.xlabel('Number of Clusters')\n",
        "plt.ylabel('Silhouette Score')\n",
        "plt.title('Silhouette Score for Different Numbers of Clusters')\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-04T13:49:15.096353Z",
          "iopub.execute_input": "2024-01-04T13:49:15.096785Z",
          "iopub.status.idle": "2024-01-04T13:49:15.431076Z",
          "shell.execute_reply.started": "2024-01-04T13:49:15.096748Z",
          "shell.execute_reply": "2024-01-04T13:49:15.429788Z"
        },
        "trusted": true,
        "id": "hgz46NTIOEME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* As per silhouette, No of Clusters = 2"
      ],
      "metadata": {
        "id": "OtZ5se8QOEME"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot inertia vs No Of centroids\n",
        "plt.plot(n_clusters_range, inertia, marker='o')\n",
        "plt.xlabel('Number of Clusters')\n",
        "plt.ylabel('Inertia')\n",
        "plt.title('Inertia for Different Numbers of Clusters')\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-04T13:49:30.858125Z",
          "iopub.execute_input": "2024-01-04T13:49:30.858579Z",
          "iopub.status.idle": "2024-01-04T13:49:31.184082Z",
          "shell.execute_reply.started": "2024-01-04T13:49:30.85854Z",
          "shell.execute_reply": "2024-01-04T13:49:31.182764Z"
        },
        "trusted": true,
        "id": "njPo-evyOEME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* As per Elbow method no of cluster: 5"
      ],
      "metadata": {
        "id": "aO4bGvd-OEMF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inertia"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-04T13:50:11.602899Z",
          "iopub.execute_input": "2024-01-04T13:50:11.603782Z",
          "iopub.status.idle": "2024-01-04T13:50:11.611145Z",
          "shell.execute_reply.started": "2024-01-04T13:50:11.60374Z",
          "shell.execute_reply": "2024-01-04T13:50:11.609973Z"
        },
        "trusted": true,
        "id": "Rl4NPbujOEMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "silhouette_scores"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-04T13:50:37.853638Z",
          "iopub.execute_input": "2024-01-04T13:50:37.854083Z",
          "iopub.status.idle": "2024-01-04T13:50:37.863409Z",
          "shell.execute_reply.started": "2024-01-04T13:50:37.854051Z",
          "shell.execute_reply": "2024-01-04T13:50:37.861849Z"
        },
        "trusted": true,
        "id": "SF1JtOItOEMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Taking optimal no of clusters as 5\n",
        "\n",
        "X = data[features_for_clustering]\n",
        "\n",
        "n_samples = len(X)\n",
        "\n",
        "# Specify the number of chunks\n",
        "n_chunks = 10\n",
        "chunk_size = n_samples // n_chunks\n",
        "\n",
        "# Initialize MiniBatchKMeans\n",
        "mbkmeans = MiniBatchKMeans(n_clusters=5, random_state=42, n_init='auto', batch_size=chunk_size)\n",
        "\n",
        "# Loop through chunks\n",
        "for i in range(n_chunks):\n",
        "    # Determine start and end index for the chunk\n",
        "    start_idx = i * chunk_size\n",
        "    end_idx = (i + 1) * chunk_size if i < n_chunks - 1 else n_samples\n",
        "\n",
        "    # Extract the chunk\n",
        "    chunk = X.iloc[start_idx:end_idx]\n",
        "\n",
        "    # Partially fit the model on the chunk\n",
        "    mbkmeans.partial_fit(chunk)\n",
        "\n",
        "# Predict clusters for all data points\n",
        "data['labels'] = mbkmeans.predict(X)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-04T14:01:46.787767Z",
          "iopub.execute_input": "2024-01-04T14:01:46.788185Z",
          "iopub.status.idle": "2024-01-04T14:01:52.938236Z",
          "shell.execute_reply.started": "2024-01-04T14:01:46.788154Z",
          "shell.execute_reply": "2024-01-04T14:01:52.937087Z"
        },
        "trusted": true,
        "id": "lxf33MVNOEMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['labels'].value_counts()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-04T14:01:53.448309Z",
          "iopub.execute_input": "2024-01-04T14:01:53.44878Z",
          "iopub.status.idle": "2024-01-04T14:01:53.52678Z",
          "shell.execute_reply.started": "2024-01-04T14:01:53.448744Z",
          "shell.execute_reply": "2024-01-04T14:01:53.525444Z"
        },
        "trusted": true,
        "id": "GDir_9xWOEMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ncI4mdHyOEMF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}